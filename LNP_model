#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue May  9 18:11:51 2017

@author: ycan
"""
#%%
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats.mstats import mquantiles

total_frames=100000
dt=0.001    # Time step
t=np.arange(0,total_frames*dt,dt) # Time vector
filter_time=.6 # The longest feature RGCs respond to is ~600ms 
filter_length=int(filter_time/dt) # Filter is filter_length frames long

def make_noise(): # Generate gaussian noise for stimulus
    return np.random.normal(0,9,total_frames) 
#stimulus=make_noise()

filter_index=3   # Change filter type here

def linear_filter(t,filter_index):    
    if filter_index==1: f=np.exp(-(t-0.15)**2/0.002)-np.exp(-(t-0.17)**2/0.001)
    elif filter_index==2: f=np.exp(-(t-0.05)**2/0.002)-2*np.exp(-(t-0.22)**2/0.001)
    elif filter_index==3: f=np.exp(-(t-0.06)**2/0.002)
    else: raise ValueError('Invalid filter index')   
    f=(f-np.mean(f))/np.sqrt(sum(f**2)) # Normalize filter
    return f[:filter_length]

filter_kernel=linear_filter(t,filter_index)
filtered=np.convolve(filter_kernel,stimulus,mode='full')[:-filter_length+1]

k=np.linspace(-30,30,1001)
nlt_index=5

def nlt(k, nlt_index):
    if   nlt_index==1: nlfunction = lambda x: (0 if x < 0 else x)
    elif nlt_index==2: nlfunction = lambda x: np.exp(x*.12)
    elif nlt_index==3: nlfunction = lambda x: -10/(1+np.exp(x-2))+10
    elif nlt_index==4: nlfunction = lambda x: (-x*.2 if x<0 else x)
    elif nlt_index==5: nlfunction = lambda x: (0.02*x**2 if x<0 else .04*x**2)
    else: raise ValueError('Invalid non-linearity index')   
    return np.array([nlfunction(x) for x in k])

def nlt2(k,nlt_index):
    if nlt_index==1:
        res=[]
        for i in k:
            if i<=0: res.append(0)
            else:    res.append(i)
    elif nlt_index==2: res= np.exp(k*.12)
    elif nlt_index==3: res= -10/(1+np.exp(k-2))+10
    elif nlt_index==4: res= np.concatenate((np.linspace(0,0,k.size/2),np.linspace(0,30,k.size/2+1)))
    elif nlt_index==5: res= np.concatenate((0.002*k[:k.size/2]**2,0.04*k[k.size/2:]**2))
    elif nlt_index==6:
        res=[]
        for i in k:
            if i<=0: res.append(-i*.9)
            else:    res.append(i)
    else: raise ValueError('Invalid non-linearity index')   
    return np.array(res)
fire_rates=np.array(nlt(filtered,nlt_index))
#Spikes
spikes=np.array([])
for i in fire_rates:
    spikes=np.append(spikes,np.random.poisson(i))
#plt.scatter(t,spikes)

print('{} spikes generated.'.format(int(sum(spikes))))
#%%
def sta(spikes,stimulus,filter_length):
    snippets=np.zeros(filter_length)
    for i in range(filter_length,total_frames):
        snippets=snippets+stimulus[i:i-filter_length:-1]*spikes[i]
    sta_unscaled=snippets/sum(spikes)   # Normalize/scale the STA
    sta_scaled=sta_unscaled/np.sqrt(sum(np.power(sta_unscaled,2)))
    return sta_scaled
recovered_kernel=sta(spikes,stimulus,filter_length)

filtered2=np.convolve(recovered_kernel,stimulus,mode='full')[:-filter_length+1]

#%% Variable bin size, log
log_bin_nr=60
logbins=np.logspace(0,np.log(30)/np.log(10),log_bin_nr)
logbins=-logbins[::-1]+logbins
logbindices=np.digitize(filtered2,logbins)
spikecount_in_logbins=np.array([])
for i in range(log_bin_nr):
    spikecount_in_logbins=np.append(spikecount_in_logbins,(np.average(spikes[np.where(logbindices==i)])))

#%% Using mquantiles
bin_nr=1000
quantiles=mquantiles(filtered2,np.linspace(0,1,bin_nr,endpoint=False))
bindices=np.digitize(filtered2,quantiles)   # Returns which bin each should go
spikecount_in_bins=np.array([])
for i in range(bin_nr): # Sorts values into bins
    spikecount_in_bins=np.append(spikecount_in_bins,(np.average(spikes[np.where(bindices==i)])))

